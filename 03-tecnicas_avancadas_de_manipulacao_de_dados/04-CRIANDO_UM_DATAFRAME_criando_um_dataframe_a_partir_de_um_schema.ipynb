{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e54b3358-11bb-480a-8608-160be933f2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a80d51dd-f593-4921-939a-66a3a29fb86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Curso de PySpark\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a642464a-4de7-4eb9-86b0-84673cb9c810",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://COLTWFGLFV04:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.5</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Curso de PySpark</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x26099cf2030>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e6e1352-88ab-4f11-9035-aa5fe4ceb91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/marlos.barros/Cursos/pyspark_na_pratica/DATASETS/LOGINS.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e762b328-cc97-41a6-9cc7-73e45212267a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"parquet\").load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4159b9d-6385-41c8-81b5-37069dcfe9f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0340a123-5a74-43c1-9140-ac7b0d8b0ec8",
   "metadata": {},
   "source": [
    "### Criar DataFrame a partir de uma lista de dicionários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2468f73-c3ce-4b7c-a0ca-dcf11f241db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = [\n",
    "    {\"nome\": \"Igor\", \"idade\": 31},\n",
    "    {\"nome\": \"Kassia\", \"idade\": 31},\n",
    "    {\"nome\": \"Gustavo\", \"idade\": 10}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19df6982-800b-4ea6-9f39-c148dff9372e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'nome': 'Igor', 'idade': 31},\n",
       " {'nome': 'Kassia', 'idade': 31},\n",
       " {'nome': 'Gustavo', 'idade': 10}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42193e03-e89b-4fa3-acbe-f1bd3075094c",
   "metadata": {},
   "source": [
    "- **Função: Cria um DataFrame do Spark a partir de uma lista de dicionários. Cada dicionário representa uma linha, e as chaves se tornam os nomes das colunas do DataFrame.** ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c04f96-6e90-4e49-b3ae-af6fa8b28675",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spark.createDataFrame(dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e645506-2488-4123-b4ab-4cccb8e7b116",
   "metadata": {},
   "source": [
    "### Criar DataFrame a partir de uma lista de tuplas e definir nomes das colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73092f56-66d4-4edd-9cbb-7bd82c572bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_2 = [\n",
    "    (\"Igor\", 31),\n",
    "    (\"Kassia\", 31),\n",
    "    (\"Gustavo\", 10)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ae387f55-c417-4c80-96e2-404f99f340d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Igor', 31), ('Kassia', 31), ('Gustavo', 10)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados_2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c82383-04c3-4833-909d-9c503d5d7b8c",
   "metadata": {},
   "source": [
    "- **Função: Cria um DataFrame do Spark a partir de uma lista de tuplas, onde cada tupla representa uma linha. Os nomes das colunas são definidos explicitamente como \"nome\" e \"idade\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9b894-4d3d-4b1a-9f41-6c91eea855af",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.createDataFrame(dados_2, [\"nome\", \"idade\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c68cde-df1b-436e-848e-32454955ba3c",
   "metadata": {},
   "source": [
    "### Criar DataFrame com esquema personalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "791170eb-2ea6-48c7-9c6c-39bd522816bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "71749e28-6a3d-4daa-b484-3a87bc77ef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = T.StructType([\n",
    "    T.StructField(\"nome\", T.StringType(), True),\n",
    "    T.StructField(\"idade\", T.StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7e3139af-461f-4e0a-9a89-a2acca34c21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('nome', StringType(), True), StructField('idade', StringType(), True)])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ca73f2-3bd1-4a4b-bcfb-9a71ede86ec6",
   "metadata": {},
   "source": [
    "- **Função: Cria um DataFrame a partir de uma lista de tuplas e define um esquema personalizado. No esquema, nome e idade são definidos como campos do tipo StringType, e o terceiro parâmetro True indica que os valores podem ser nulos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7816aee-f9dd-4c64-9639-0893e7ae6309",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.createDataFrame(dados_2, schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad701ee-c97e-43eb-86b9-cc79fd1e0055",
   "metadata": {},
   "source": [
    "### Criar DataFrame a partir de uma lista de objetos Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1eee7470-f035-482d-9f1e-cc743bb83528",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d7a4a31c-6631-476a-9774-a7cfe0d0118f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = [\n",
    "    Row(\"Igor\", 31),\n",
    "    Row(\"Kassia\", 31)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7d5fd598-aa33-4ef7-826b-f39e7c7ced0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Row('Igor', 31)>, <Row('Kassia', 31)>]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4d43f6-d719-4bd4-9df4-aa71be11d09a",
   "metadata": {},
   "source": [
    "- **Função: Cria um DataFrame usando uma lista de objetos Row do PySpark. Aqui, os valores são atribuídos aos campos \"_1\" e \"_2\", com seus respectivos tipos string e int.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24febea6-53c6-457e-affb-82b42392670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.createDataFrame(rdd, \"_1: string, _2: int\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

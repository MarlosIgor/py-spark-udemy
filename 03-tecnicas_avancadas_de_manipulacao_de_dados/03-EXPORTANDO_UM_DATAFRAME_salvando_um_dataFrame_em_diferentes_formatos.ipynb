{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d85708d1-ed80-42b0-9374-ef947093661f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as F\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44978493-7c5f-417b-a30c-40272bc3061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder\n",
    "    .appName(\"Curso de PySpark\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True)\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de16527-71fa-4d4a-bbb3-879df9379dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2871a63-7047-439b-82d4-8ea5f6370159",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/marlos.barros/Cursos/pyspark_na_pratica/DATASETS/LOGINS.parquet\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd98aecf-bad5-429a-9466-26c33c7504aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"parquet\").load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9271b7ef-eb17-40d3-8002-03defcf885b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2002763-85c8-4c2d-b4a8-fb4241e13631",
   "metadata": {},
   "source": [
    "### Salvar DataFrame sem particionamento\n",
    "- Função: Salva o DataFrame **df** no diretório **\"output\"** no formato padrão do **Spark (Parquet)**, sem particionamento ou sobrescrita."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a683ef-af77-41b0-97e3-30859d67862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.save(\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329186e2-c0c1-414c-8bee-858054f730fb",
   "metadata": {},
   "source": [
    "### Salvar DataFrame particionado por \"estado\"\n",
    "- Função: Salva o DataFrame **df** no diretório **\"output\"** em formato **Parquet**, **sobrescrevendo os dados existentes**. As partições são criadas com base na coluna **estado**, separando os dados em diferentes diretórios por **estado**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e30de1f-d951-43a0-95dd-4f18040f996d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode(\"overwrite\").format(\"parquet\").partitionBy(\"estado\").save(\"output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6708bd0-86e1-4956-b18f-dae5e680a443",
   "metadata": {},
   "source": [
    "### Salvar DataFrame com parâmetros no save\n",
    "- Função: Uma maneira alternativa de salvar o DataFrame **df**, passando os parâmetros **mode**, format e **partitionBy()** diretamente no método **save()**. O comportamento é semelhante ao exemplo anterior, sobrescrevendo dados e particionando por estado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2807e5-c85d-4179-82d5-ba38e985383e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.save(\"output\", mode=\"overwrite\", format=\"parquet\", partitionBy=\"estado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a59fb0-f3fe-4889-b465-147b707959bb",
   "metadata": {},
   "source": [
    "### Salvar DataFrame particionado por ano e mês de nascimento\n",
    "- Função: Adiciona colunas para o **ano** e o **mês** da coluna **data_de_nascimento** no DataFrame **df**, e em seguida, salva o **DataFrame** no caminho especificado. O salvamento é feito no **formato Parquet**, particionado por **ano** e **mes**. O **modo()** **append** é usado para **adicionar os dados sem sobrescrever**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2999a1d-6a96-4f0d-b8a9-a67b80b6692f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/marlos.barros/Cursos/pyspark_na_pratica/03-tecnicas_avancadas_de_manipulacao_de_dados/output\"\n",
    "\n",
    "(\n",
    "    df\n",
    "    .withColumn(\"ano\", F.year(\"data_de_nascimento\"))\n",
    "    .withColumn(\"mes\", F.month(\"data_de_nascimento\"))\n",
    "    .write.mode(\"append\").partitionBy(\"ano\", \"mes\").format(\"parquet\").save(path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1494ad45-c36b-4cd6-8b16-5c78481e4387",
   "metadata": {},
   "source": [
    "### Salvar DataFrame como Parquet com parquet()\n",
    "- Função: Similar ao exemplo anterior, mas usa o método **parquet()** diretamente para salvar o DataFrame no formato **Parquet**, particionado por **ano** e **mês**, com o **modo append**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3f52b3b-c0dc-4944-93e8-92f191a852f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/marlos.barros/Cursos/pyspark_na_pratica/03-tecnicas_avancadas_de_manipulacao_de_dados/output\"\n",
    "\n",
    "(\n",
    "    df\n",
    "    .withColumn(\"ano\", F.year(\"data_de_nascimento\"))\n",
    "    .withColumn(\"mes\", F.month(\"data_de_nascimento\"))\n",
    "    .write.mode(\"append\").partitionBy(\"ano\", \"mes\").parquet(path)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae0b587-d27d-453b-b420-1d1dbc63ab51",
   "metadata": {},
   "source": [
    "### Converter DataFrame para CSV\n",
    "- Função: Converte o DataFrame **df** para um DataFrame **pandas** e o salva no **formato CSV** no arquivo **\"output.csv\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f91049c-2cb7-44d9-8c24-e78b7c8584f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.toPandas().to_csv(\"output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f09cbcd-d2e1-4493-8240-a16f0352d97b",
   "metadata": {},
   "source": [
    "### Converter DataFrame para Excel\n",
    "- Função: Converte o DataFrame **df** para um DataFrame **pandas** e o salva em um arquivo **Excel** com o nome **\"output.xlsx\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "40bb338c-407b-49d7-86c3-f575eed4de8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.toPandas().to_excel(\"output.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96511211-9cf7-4253-b7e5-dc20e98bffef",
   "metadata": {},
   "source": [
    "### Converter DataFrame para Parquet usando pandas\n",
    "- Função: Converte o DataFrame **df** para **pandas** e o salva no formato **Parquet** diretamente com **pandas** no arquivo **\"output.parquet\"**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "de161350-7c68-488f-b7b4-b975afdbdb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.toPandas().to_parquet(\"output.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
